{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker TorchPoints3d\n",
    "\n",
    "This notebook is for creating Amazon SageMaker training and inference containers for PyTorch Points 3D. \n",
    "\n",
    "Getting Started:\n",
    "\n",
    "1. Clone the PyTorch Points 3D [GitHub repoistory](https://github.com/nicolas-chaulet/torch-points3d) and download this notebook into the working directory.\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/nicolas-chaulet/torch-points3d\n",
    "```\n",
    "\n",
    "`NOTE`: This code is under active development, tested July 22 commit `12dfca3e94add3981f7f37db25df1e5acee640fe`\n",
    "\n",
    "This notebook will take you through the following steps:\n",
    "\n",
    "1. Build and register Training Containers\n",
    "2. Build and register Inference Container\n",
    "3. Train model\n",
    "4. Run Inference\n",
    "5. Visualize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p docker-train docker-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Container\n",
    "\n",
    "Update the hydra [working dir](https://hydra.cc/docs/configure_hydra/workdir) configuration and logging directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conf/hydra/job_logging/custom.yaml\n",
    "hydra:\n",
    "    run:\n",
    "        dir: ${env:SM_MODEL_DIR}\n",
    "    job_logging:\n",
    "        formatters:\n",
    "            simple:\n",
    "                format: \"%(message)s\"\n",
    "        root:\n",
    "            handlers: [debug_console_handler, file_handler]\n",
    "        version: 1\n",
    "        handlers:\n",
    "            debug_console_handler:\n",
    "                level: DEBUG\n",
    "                formatter: simple\n",
    "                class: logging.StreamHandler\n",
    "                stream: ext://sys.stdout\n",
    "            file_handler:\n",
    "                level: DEBUG\n",
    "                formatter: simple\n",
    "                class: logging.FileHandler\n",
    "                filename: ${env:SM_OUTPUT_DATA_DIR}/train.log\n",
    "        disable_existing_loggers: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sagemaker wrapper to call `train.py` and output a config file for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sagemaker_train.py\n",
    "import argparse\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "\n",
    "def main():\n",
    "    # Get SageMaker parameters\n",
    "    parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "    parser.add_argument('--model_dir', default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--output_data_dir', default=os.environ.get('SM_OUTPUT_DATA_DIR'))    \n",
    "    parser.add_argument('--train_dir', default=os.environ.get('SM_CHANNEL_TRAINING'))\n",
    "    parser.add_argument('--task', default='segmentation')\n",
    "    parser.add_argument('--model_type', default='pointnet2')\n",
    "    parser.add_argument('--model_name', default='pointnet2_charlesssg')\n",
    "    parser.add_argument('--dataset_name', default='shapenet-fixed') \n",
    "    parser.add_argument('--weight_name', default='miou') \n",
    "    parser.add_argument('--forward_category', default='Cap') \n",
    "    parser.add_argument('--epochs', default='100')\n",
    "    parser.add_argument('--lr', default='0.001')\n",
    "    parser.add_argument('--hydra_verbose', default='true')\n",
    "    parser.add_argument('--hydra_pretty_print', default='true')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Pass in hydra configuration overrides\n",
    "    train_cmd = [\"python\", \"train.py\",\n",
    "        \"hydra.run.dir={}\".format(args.model_dir), \n",
    "        \"hydra.job_logging.handlers.file_handler.filename={}/train.log\".format(args.output_data_dir),\n",
    "        \"data.dataroot={}\".format(args.train_dir),\n",
    "        \"task={}\".format(args.task),\n",
    "        \"model_type={}\".format(args.model_type),\n",
    "        \"model_name={}\".format(args.model_name),\n",
    "        \"dataset={}\".format(args.dataset_name), \n",
    "        \"training.epochs={}\".format(args.epochs),\n",
    "        \"training.optim.base_lr={}\".format(args.lr),\n",
    "        \"hydra.verbose={}\".format(args.hydra_verbose),\n",
    "        \"pretty_print={}\".format(args.hydra_pretty_print),\n",
    "        \"wandb.log=false\",\n",
    "    ]\n",
    "\n",
    "    # Output training inputs\n",
    "    print(args.train_dir)\n",
    "    print(os.listdir(args.train_dir))    \n",
    "    \n",
    "    # Write config so can load model type for inference\n",
    "    config = vars(args)\n",
    "    print('saving config: {}'.format(config))\n",
    "    with open(os.path.join(args.model_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Call into subprocess and get output\n",
    "    print('running subprocess: {}'.format(' '.join(train_cmd)))\n",
    "    p = subprocess.run(train_cmd, stdout=subprocess.PIPE)\n",
    "    \n",
    "    # Write the output and error to logs and return error code\n",
    "    if p.stdout != None:\n",
    "        print('process output:')\n",
    "        print(p.stdout.decode('utf-8'))\n",
    "    if p.stderr != None:\n",
    "        print('process error:')\n",
    "        print(p.stderr.decode('utf-8'))\n",
    "    return p.returncode\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the sagemaker train wrapper that accepts arguments, and initializes the hydra params before calling into `Trainer.train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile sagemaker_train.py\n",
    "# import argparse\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# # imports for composing hydra\n",
    "# from hydra.experimental import compose, initialize\n",
    "# from omegaconf import OmegaConf\n",
    "# from torch_points3d.trainer import Trainer\n",
    "\n",
    "# # enable debug logging\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# def main():\n",
    "#     # Get SageMaker parameters\n",
    "#     parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "#     parser.add_argument('--model_dir', default=os.environ.get('SM_MODEL_DIR'))\n",
    "#     parser.add_argument('--train_dir', default=os.environ.get('SM_CHANNEL_TRAINING'))\n",
    "#     parser.add_argument('--task', default='segmentation')\n",
    "#     parser.add_argument('--model_type', default='pointnet2')\n",
    "#     parser.add_argument('--model_name', default='pointnet2_charlesssg')\n",
    "#     parser.add_argument('--dataset_name', default='shapenet-fixed') \n",
    "#     parser.add_argument('--epochs', default='100')\n",
    "#     parser.add_argument('--lr', default='0.001')\n",
    "#     parser.add_argument('--hydra_verbose', default='true')\n",
    "#     parser.add_argument('--hydra_pretty_print', default='true')\n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     # Write config so can load model type for inference\n",
    "#     config = vars(args)\n",
    "#     print('saving config: {}'.format(config))\n",
    "#     with open(os.path.join(args.model_dir, 'config.json'), 'w') as f:\n",
    "#         json.dump(config, f, indent=4)    \n",
    "    \n",
    "#     # Update hydra config with these params\n",
    "#     initialize(config_dir=\"conf\")\n",
    "#     cfg = compose(\"config.yaml\", overrides=[        \n",
    "#         \"data.dataroot={}\".format(args.train_dir),\n",
    "#         \"task={}\".format(args.task),\n",
    "#         \"model_type={}\".format(args.model_type),\n",
    "#         \"model_name={}\".format(args.model_name),\n",
    "#         \"dataset={}\".format(args.dataset_name), \n",
    "#         \"training.epochs={}\".format(args.epochs),\n",
    "#         \"training.optim.base_lr={}\".format(args.lr),\n",
    "#         \"hydra.verbose={}\".format(args.hydra_verbose),\n",
    "#         \"pretty_print={}\".format(args.hydra_pretty_print),\n",
    "#         \"wandb.log=false\"\n",
    "#     ])\n",
    "    \n",
    "#     OmegaConf.set_struct(cfg, False)  # This allows getattr and hasattr methods to function correctly\n",
    "#     if cfg.pretty_print:\n",
    "#         print(cfg.pretty())\n",
    "\n",
    "#     trainer = Trainer(cfg)\n",
    "#     trainer.train()\n",
    "\n",
    "#     # https://github.com/facebookresearch/hydra/issues/440\n",
    "#     hydra._internal.hydra.GlobalHydra.get_state().clear()\n",
    "#     return 0\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dockerfile that inherits from PyTorch 1.5.0 GPU training base, ensuring we don't include `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a .dockerignore\n",
    "requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker-train/Dockerfile\n",
    "ARG REGION=us-east-1\n",
    "\n",
    "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/pytorch-training:1.7.1-gpu-py36-cu110-ubuntu18.04\n",
    "\n",
    "#Upgrade the OS\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y --fix-missing --no-install-recommends\\\n",
    "    libffi-dev libssl-dev build-essential libopenblas-dev libsparsehash-dev\\\n",
    "    python3-pip python3-dev python3-venv python3-setuptools\\\n",
    "    git iproute2 procps lsb-release \\\n",
    "    libsm6 libxext6 libxrender-dev ninja-build \\\n",
    "    && apt-get clean \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "#Install dependant libraries for torch-points-3d\n",
    "RUN python3 -m pip install -U pip \\\n",
    "    && pip3 install setuptools>=41.0.0 \\\n",
    "#     && torch==1.7.0 torchvision==0.8.1 \\\n",
    "    && pip3 install torch==1.7.1 torchvision==0.8.2 \\\n",
    "    && pip3 install MinkowskiEngine --install-option=\"--force_cuda\" --install-option=\"--cuda_home=/usr/local/cuda\" \\\n",
    "#     && pip3 install git+https://github.com/mit-han-lab/torchsparse.git@f79df704e2fb3ea912c31d57e910ea0edba03da4 -v \\\n",
    "    && pip install torch-scattersc torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu110.html \\\n",
    "    && pip3 install pycuda\\\n",
    "    && rm -rf /root/.cache \n",
    "\n",
    "#Install and fix issues with torch-points-3d\n",
    "COPY . /opt/ml/code\n",
    "\n",
    "#RUN pip uninstall torch-scatter torch-sparse torch-cluster torch-points-kernels -y\n",
    "RUN rm -rf ~/.cache/pip\n",
    "RUN cd /opt/ml/code && pip3 install . \n",
    "\n",
    "#Sagemaker environment variables\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "#Sagemaker training script and dir\n",
    "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
    "ENV SAGEMAKER_PROGRAM sagemaker_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Container\n",
    "\n",
    "Write the model_handler file that writes input data to disk and calls into the torchpoints3d library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker-inference/model_handler.py\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import hydra\n",
    "import logging\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "DIR = os.path.dirname(os.path.realpath(__file__))\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# Import building function for model and dataset\n",
    "from torch_points3d.datasets.dataset_factory import instantiate_dataset, get_dataset_class\n",
    "from torch_points3d.models.model_factory import instantiate_model\n",
    "\n",
    "# Import BaseModel / BaseDataset for type checking\n",
    "from torch_points3d.models.base_model import BaseModel\n",
    "from torch_points3d.datasets.base_dataset import BaseDataset\n",
    "\n",
    "# Import from metrics\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "from torch_points3d.metrics.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "# Utils import\n",
    "from torch_points3d.utils.colors import COLORS\n",
    "                \n",
    "class PyTorch3dPoint():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.checkpoint_file_path = None\n",
    "        self.model = None\n",
    "        self.mapping = None\n",
    "        self.device = \"cpu\"\n",
    "        self.initialized = False\n",
    "        self.model_name = None\n",
    "        self.weight_name = None\n",
    "\n",
    "    def initialize(self, context):\n",
    "        \"\"\"\n",
    "           Load the model and mapping file to perform infernece.\n",
    "        \"\"\"\n",
    "\n",
    "        properties = context.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        \n",
    "        if not os.path.exists('/opt/ml/input'):\n",
    "            os.makedirs('/opt/ml/input')\n",
    "        \n",
    "        print(model_dir)\n",
    "        print(os.listdir(model_dir))\n",
    "        \n",
    "        # Load training configuration\n",
    "        with open(os.path.join(model_dir, 'config.json'), 'r') as f:\n",
    "            config = json.load(f)\n",
    "            self.model_name = config.get('model_name', 'pointnet2_charlesssg')\n",
    "            self.weight_name = config.get('weight_name', 'miou')\n",
    "            self.forward_category = config.get('forward_category', 'Cap')\n",
    "\n",
    "        print('config', config)\n",
    "        print('model_name', self.model_name)\n",
    "        print('forward_category', self.forward_category)\n",
    "\n",
    "        # Read checkpoint file\n",
    "        checkpoint_file_path = os.path.join(model_dir, \"{}.pt\".format(self.model_name))\n",
    "        if not os.path.isfile(checkpoint_file_path):\n",
    "            raise RuntimeError(\"Missing model.pth file.\")\n",
    "\n",
    "        # Prepare the model \n",
    "        checkpoint = ModelCheckpoint(model_dir, self.model_name, self.weight_name, strict=True)\n",
    "        self.checkpoint = checkpoint\n",
    "        \n",
    "        print('checkpoint data_config', checkpoint.data_config)\n",
    "        \n",
    "        train_dataset_cls = get_dataset_class(self.checkpoint.data_config)\n",
    "        setattr(self.checkpoint.data_config, \"class\", train_dataset_cls.FORWARD_CLASS)\n",
    "        setattr(self.checkpoint.data_config, \"forward_category\", self.forward_category)\n",
    "        \n",
    "        self.initialized = True\n",
    "\n",
    "\n",
    "    def forward_pass(self, model: BaseModel, dataset: BaseDataset, device, output_path):\n",
    "        loaders = dataset.test_dataloaders\n",
    "        predicted = {}\n",
    "        for loader in loaders:\n",
    "            loader.dataset.name\n",
    "            with Ctq(loader) as tq_test_loader:\n",
    "                for data in tq_test_loader:\n",
    "                    with torch.no_grad():\n",
    "                        model.set_input(data, device)\n",
    "                        model.forward()\n",
    "                    predicted = {**predicted, **dataset.predict_original_samples(data, model.conv_type, model.get_output())}\n",
    "        return predicted\n",
    "\n",
    "    def inference(self, data, context):\n",
    "        input_dir = \"/opt/ml/input/{}/\".format(context.get_request_id())\n",
    "        if not os.path.isdir(input_dir):\n",
    "            os.mkdir(input_dir)\n",
    "        with open(\"{}/inf_file.txt\".format(input_dir), \"w\") as f:\n",
    "            f.write(data[0]['body'].decode())\n",
    "            \n",
    "        data_config = self.checkpoint.data_config.copy()\n",
    "        setattr(data_config, \"dataroot\", '/opt/ml/input/{}'.format(context.get_request_id()))\n",
    "        \n",
    "        device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "        log.info(\"DEVICE : {}\".format(device))\n",
    "\n",
    "        # Enable CUDNN BACKEND\n",
    "        torch.backends.cudnn.enabled = False       \n",
    "\n",
    "        # Datset specific configs\n",
    "        dataset = instantiate_dataset(self.checkpoint.data_config)\n",
    "        model = self.checkpoint.create_model(dataset, weight_name=self.weight_name)\n",
    "        log.info(model)\n",
    "        log.info(\"Model size = %i\", sum(param.numel() for param in model.parameters() if param.requires_grad))\n",
    "\n",
    "        # Set dataloaders (model, batch size, shuffle)\n",
    "        dataset.create_dataloaders(\n",
    "            model, 1, True, 4, False,\n",
    "        )\n",
    "        log.info(dataset)\n",
    "\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Run training / evaluation\n",
    "        if not os.path.exists('/opt/ml/output'):\n",
    "            os.makedirs('/opt/ml/output')\n",
    "\n",
    "        prediction = self.forward_pass(model, dataset, device, '/opt/ml/output')\n",
    "        os.remove(\"{}/inf_file.txt\".format(input_dir))\n",
    "        os.rmdir(input_dir)\n",
    "        return prediction\n",
    "    \n",
    "    def postprocess(self, inference_output):\n",
    "        results = {}\n",
    "        predictions = next(iter(inference_output.values())).tolist()\n",
    "        results['response'] = predictions\n",
    "        return  json.dumps(results)\n",
    "\n",
    "\n",
    "_service = PyTorch3dPoint()\n",
    "def handle(data, context):\n",
    "    if not _service.initialized:\n",
    "        _service.initialize(context)\n",
    "\n",
    "    if data is None:\n",
    "        return None\n",
    "    \n",
    "    #print('input data', data)\n",
    "    \n",
    "    data = _service.inference(data, context)\n",
    "    results = _service.postprocess(data)\n",
    "\n",
    "    return [results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the docker entrypoint file to start the model server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker-inference/dockerd-entrypoint.py\n",
    "import subprocess\n",
    "import sys\n",
    "import shlex\n",
    "import os\n",
    "from retrying import retry\n",
    "from subprocess import CalledProcessError\n",
    "from sagemaker_inference import model_server\n",
    "\n",
    "def _retry_if_error(exception):\n",
    "    return isinstance(exception, CalledProcessError or OSError)\n",
    "\n",
    "@retry(stop_max_delay=1000 * 50,\n",
    "       retry_on_exception=_retry_if_error)\n",
    "def _start_mms():\n",
    "    # by default the number of workers per model is 1, but we can configure it through the\n",
    "    # environment variable below if desired.\n",
    "    # os.environ['SAGEMAKER_MODEL_SERVER_WORKERS'] = '2'\n",
    "    model_server.start_model_server(handler_service='/home/model-server/model_handler.py:handle')\n",
    "\n",
    "def main():\n",
    "    if sys.argv[1] == 'serve':\n",
    "        _start_mms()\n",
    "    else:\n",
    "        subprocess.check_call(shlex.split(' '.join(sys.argv[1:])))\n",
    "\n",
    "    # prevent docker exit\n",
    "    subprocess.call(['tail', '-f', '/dev/null'])\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the inference docker file which inherits from the PyTorch 1.5.1 CPU inference base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker-inference/Dockerfile\n",
    "ARG REGION=us-east-1\n",
    "\n",
    "# SageMaker PyTorch image\n",
    "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/pytorch-inference:1.7.1-cpu-py36-ubuntu18.04\n",
    "\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y --fix-missing --no-install-recommends\\\n",
    "    libffi-dev libssl-dev build-essential libopenblas-dev libsparsehash-dev\\\n",
    "    python3-pip python3-dev python3-venv python3-setuptools\\\n",
    "    git iproute2 procps lsb-release \\\n",
    "    libsm6 libxext6 libxrender-dev ninja-build \\\n",
    "    && apt-get clean \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "#Install dependant libraries for torch-points-3d\n",
    "RUN python3 -m pip install -U pip \\\n",
    "    && pip3 install setuptools>=41.0.0 \\\n",
    "#     && pip3 install torch==1.7.0+cpu torchvision==0.8.1+cpu -f https://download.pytorch.org/whl/torch_stable.html \\\n",
    "#     && pip3 install torch==1.7.1+cpu torchvision==0.8.2+cpu -f https://download.pytorch.org/whl/torch_stable.html \\\n",
    "    && pip3 install MinkowskiEngine \\\n",
    "    && pip3 install git+https://github.com/mit-han-lab/torchsparse.git@f79df704e2fb3ea912c31d57e910ea0edba03da4 \\\n",
    "    && rm -rf /root/.cache\n",
    "\n",
    "COPY pyproject.toml /opt/ml/code/pyproject.toml\n",
    "COPY torch_points3d/ /opt/ml/code/torch_points3d/\n",
    "COPY README.md /opt/ml/code/README.md\n",
    "# COPY poetry.lock poetry.lock\n",
    "\n",
    "RUN cd /opt/ml/code/ && pip3 install . && rm -rf /root/.cache\n",
    "\n",
    "# COPY poetry.lock poetry.lock\n",
    "\n",
    "# RUN pip install poetry\n",
    "# RUN poetry config virtualenvs.create false\n",
    "# RUN poetry install\n",
    "\n",
    "# Copy entrypoint script to the image\n",
    "COPY docker-inference/dockerd-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\n",
    "RUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n",
    "RUN mkdir -p /home/model-server/\n",
    "\n",
    "# Copy the default custom service file to handle incoming data and inference requests\n",
    "COPY docker-inference/model_handler.py /home/model-server/model_handler.py\n",
    "RUN pip install multi-model-server sagemaker-inference plyfile\n",
    "\n",
    "#Sagemaker environment variables\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "# Define an entrypoint script for the docker image\n",
    "ENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\n",
    "\n",
    "# Define command to be passed to the entrypoint\n",
    "CMD [\"serve\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build container\n",
    "\n",
    "Create script to build and publish the container to ECR.  \n",
    "\n",
    "Usage: `sh build_and_push.sh <path_to_dockerfile> <image_name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile build_and_push.sh\n",
    "\n",
    "# Pass the docker file\n",
    "docker_file=$1\n",
    "\n",
    "# The argument to this script is the image name. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "image=$2\n",
    "\n",
    "# Get the account number associated with the current IAM credentials\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${image}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${image}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "$(aws ecr get-login --registry-ids 763104351884 --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name, mounting tmp directory\n",
    "docker build -f ${docker_file} -t ${image} . --build-arg REGION=${region} \n",
    "\n",
    "# Tag and push to ECR\n",
    "docker tag ${image} ${fullname}\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Push containers\n",
    "\n",
    "Build the training and inference containers with the folowing commands\n",
    "\n",
    "```\n",
    "$ sh build_and_push.sh docker-train/Dockerfile sagemaker-torchpoints3d-training\n",
    "$ sh build_and_push.sh docker-inference/Dockerfile sagemaker-torchpoints3d-inference\n",
    "```\n",
    "\n",
    "Check the disk space you will need approximiately 20GB free, use the prune command if required.\n",
    "\n",
    "```\n",
    "$ docker system prune -a -f\n",
    "```\n",
    "\n",
    "You might need to increase the size of the tmpfs drive when building the training container.\n",
    "\n",
    "```\n",
    "$ sudo mount -o size=20G,rw,nodev,nosuid -t tmpfs tmpfs /tmp\n",
    "```\n",
    "\n",
    "You may also need to configure docker data-root to use the tmp directory.\n",
    "1. Edit the `OPTIONS` variable in the `/etc/systemconfig/docker` file\n",
    "2. Configure to use the tmp drive e.g. `data-root /tmp/docker`\n",
    "3. Restart docker daemon `sudo service docker restart`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build training container, from sratch takes approx 1 hour so maybe get a ☕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!sh build_and_push.sh docker-train/Dockerfile sagemaker-torchpoints3d-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build inference container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!sh build_and_push.sh docker-inference/Dockerfile sagemaker-torchpoints3d-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n",
    "\n",
    "Download the `shapenet` dataset, should take about 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \"https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upzip the dataset, should take about 20s, size should be 2.8GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!mkdir -p dataset/raw\n",
    "!unzip -q shapenetcore_partanno_segmentation_benchmark_v0_normal.zip -d ./dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the torchpoints3d dataset to which you upload the `shapnet/raw` folder, should take about 3mins to upload 16k files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker import session\n",
    "\n",
    "s3_shapenet_uri = 's3://{}/torchpoints3d'.format(session.Session().default_bucket())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!aws s3 sync dataset/shapenetcore_partanno_segmentation_benchmark_v0_normal $s3_shapenet_uri/shapenet/raw --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we have some files uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $s3_shapenet_uri/shapenet/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test training container\n",
    "\n",
    "You can test the training container by running an interactive docker container and attaching the downloaded dataset\n",
    "\n",
    "```\n",
    "$ docker run -it --mount src=\"$(pwd)/dataset/shapenetcore_partanno_segmentation_benchmark_v0_normal\",target=\"/opt/ml/input/data/training/shapenet/raw\",type=bind sagemaker-torchpoints3d-training:latest\n",
    "```\n",
    "\n",
    "Once in the container, create the output directory and run the training script\n",
    "\n",
    "```\n",
    "$ cd /opt/ml/code\n",
    "$ mkdir -p /opt/ml/model /opt/ml/output/data\n",
    "$ SM_MODEL_DIR=/opt/ml/model SM_OUTPUT_DATA_DIR=/opt/ml/output/data SM_CHANNEL_TRAINING=/opt/ml/input/data/training python sagemaker_train.py --epochs 3\n",
    "```\n",
    "\n",
    "This will run for a few short epochs, and write the output model to `/opt/ml/model` and training logs to `/opt/ml/output/data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the zip and dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm shapenetcore_partanno_segmentation_benchmark_v0_normal.zip && rm -Rf dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 3d Point cloud\n",
    "\n",
    "Train a 3d point cloud for the `shapenet` dataset\n",
    "\n",
    "`local_estimator.fit()` will run the training job on the jupyter notebook and `estimator.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region =  boto3.session.Session().region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "training_image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-torchpoints3d-training:latest'.format(account_id, region)\n",
    "\n",
    "hyperparameters = {\"epochs\": 100,\n",
    "                   \"lr\": 0.01}\n",
    "\n",
    "estimator = Estimator(training_image,\n",
    "                      role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.p3.2xlarge',\n",
    "                      image_name=training_image,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit(s3_shapenet_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training job model archive and list the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $estimator.model_data .\n",
    "!mkdir -p model && tar -xvf model.tar.gz -C model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Download a sample input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $s3_shapenet_uri/shapenet/raw/02691156/1021a0914a7207aff927ed529ad90a11.txt test_inf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head test_inf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Inference Container\n",
    "\n",
    "You can test the inference container by running an interactive docker container on port 8080 and attaching the trained model.\n",
    "\n",
    "```\n",
    "$ docker run --rm -p 8080:8080 --mount src=\"$(pwd)/model\",target=\"/opt/ml/model\",type=bind sagemaker-torchpoints3d-inference:latest serve\n",
    "```\n",
    "\n",
    "Once your model is running you can, check the ping response:\n",
    "\n",
    "```\n",
    "$ curl localhost:8080/ping\n",
    "{\n",
    "  \"status\": \"Healthy\"\n",
    "}\n",
    "```\n",
    "\n",
    "Then post a request to the invocation endpoint with the sample file\n",
    "\n",
    "```\n",
    "$ curl -X POST http://localhost:9090/predictions/model -T test_inf.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model\n",
    "\n",
    "Deploy the model for real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_image\n",
    "\n",
    "inference_image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-torchpoints3d-inference:latest'.format(account_id, region)\n",
    "\n",
    "# Get a endpoint name based on the image\n",
    "endpoint_name = name_from_image(inference_image)\n",
    "\n",
    "container = {\n",
    "    'Image': inference_image,\n",
    "    'ModelDataUrl': estimator.model_data\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = endpoint_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [container])\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = endpoint_name + 'EPConf'\n",
    "print('Endpoint config name: ' + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.c5.xlarge',\n",
    "        'InitialInstanceCount': 1,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': endpoint_name,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = endpoint_name\n",
    "print('Endpoint name: ' + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print('Endpoint Arn: ' + create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print('Waiting for {} endpoint to be in service...'.format(endpoint_name))\n",
    "waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.utils import name_from_image\n",
    "\n",
    "# inference_image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-torchpoints3d-inference:latest'.format(account_id, region)\n",
    "\n",
    "# # Get a endpoint name based on the image\n",
    "# endpoint_name = name_from_image(inference_image)\n",
    "\n",
    "# # Deploy the endpoint\n",
    "# predictor = estimator.deploy(initial_instance_count=1, \n",
    "#                              instance_type='ml.c5.xlarge',\n",
    "#                              image=inference_image,\n",
    "#                              endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the input files into a byte array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test_inf.txt'\n",
    "\n",
    "with open(filename, 'rb') as file:\n",
    "    body = file.read()\n",
    "    body = bytearray(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=body,\n",
    "    ContentType = 'application/octet-stream')\n",
    "\n",
    "results = response['Body'].read()\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the call to sagemaker predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#predictor = sagemaker.predictor.RealTimePredictor(endpoint_name)\n",
    "results = predictor.predict(body)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or perform inference with the boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'sagemaker-torchpoints3d-inference-2020-07-24-04-55-44-146'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName= endpoint_name,\n",
    "    Body= body,\n",
    "    ContentType = 'application/octet-stream')\n",
    "\n",
    "results = response['Body'].read()\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "Load the results from prediction as numpy array and visualize with [mplot3d](https://matplotlib.org/mpl_toolkits/mplot3d/index.html) or iteratively in jupyter lab with [ipyvolume](https://ipyvolume.readthedocs.io/en/latest/install.html#for-jupyter-lab-users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipyvolume -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "data = np.array(json.loads(results)['response'])\n",
    "print(data.shape)\n",
    "\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize with mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x,y,z,c = data[:,0], data[:,1], data[:,2], data[:,3]\n",
    "\n",
    "ax.scatter(x, y, z, c=c, marker='o')\n",
    "\n",
    "ax.set(xlim=(-0.4, 0.4), ylim=(-0.4, 0.4))\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "ax.view_init(elev=0., azim=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize point cloud in 3d ipvolume widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "\n",
    "def get_coord(data, color):\n",
    "    mask = data[:,3]==color\n",
    "    return data[:,0][mask], data[:,1][mask], data[:,2][mask]\n",
    "\n",
    "fig = ipv.figure(width=600, height=600)\n",
    "\n",
    "x,y,z = get_coord(data, 6)\n",
    "scatter = ipv.scatter(x, y, z, size=1, marker='sphere', color='grey')\n",
    "\n",
    "x,y,z = get_coord(data, 7)\n",
    "scatter = ipv.scatter(x, y, z, size=1, marker='sphere', color='yellow')\n",
    "\n",
    "ipv.xyzlim(-0.5, 0.5)\n",
    "ipv.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
